{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MSTC_NLP_Word_Embeddings_tSNE.ipynb","version":"0.3.2","provenance":[{"file_id":"1ossNQSrXyvkmF7ZvZr7QPryk49A9tpCX","timestamp":1521206578358}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"dUNKDytx2E6E","colab_type":"text"},"cell_type":"markdown","source":["# Visualizing <font color= #13c113  >Word2Vect </font>  with <font color= #00c1FF  >t-SNE</font>\n","\n","![Word Embeddings t-SNE](https://jp.mathworks.com/help/examples/textanalytics/win64/VisualizeWordEmbeddingsUsingTextScatterPlotsExample_05.png)\n","\n","\n","## Adapted from:\n","\n","https://medium.com/@aneesha/using-tsne-to-plot-a-subset-of-similar-words-from-word2vec-bb8eeaea6229\n","\n","\n","<br>\n","\n","\n","# * [MSTC](http://mstc.ssr.upm.es/big-data-track) and MUIT: <font size=5 color='green'>Deep Learning with Tensorflow & Keras</font>"]},{"metadata":{"id":"wdRWnmNVHE8q","colab_type":"text"},"cell_type":"markdown","source":["https://medium.com/@aneesha/using-tsne-to-plot-a-subset-of-similar-words-from-word2vec-bb8eeaea6229\n","\n","## 1. Loads a pre-trained word2vec embedding\n","## 2. Finds similar words and appends each of the similar words embedding vector to the matrix\n","## 3. Applies TSNE to the Matrix to project each word to a 2D space (i.e. dimension reduction)\n","## 4. Plots the 2D position of each word with a label\n","\n","\n"]},{"metadata":{"id":"Rem3IlbGNHsv","colab_type":"text"},"cell_type":"markdown","source":["\n","---\n","# <font color=#003950 >We can use word2vec pre-trained Google News corpus (3 billion running words) word vector model (3 million 300-dimension English word vectors).</font>\n","---\n","\n"]},{"metadata":{"id":"ANCEEMPBHnZE","colab_type":"code","colab":{}},"cell_type":"code","source":["! wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ykq2cHKcMMKj","colab_type":"text"},"cell_type":"markdown","source":["# [Gensim](https://radimrehurek.com/gensim/) is a free Python library designed to automatically extract semantic topics from documents, as efficiently (computer-wise) and painlessly (human-wise) as possible\n","![gensim](https://radimrehurek.com/gensim/_static/images/gensim.png)"]},{"metadata":{"id":"lmQF4aQTH6Z2","colab_type":"code","colab":{}},"cell_type":"code","source":["! pip install gensim"],"execution_count":0,"outputs":[]},{"metadata":{"id":"udKhKAVUHgDM","colab_type":"code","colab":{}},"cell_type":"code","source":["import gensim\n","\n","model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"go0hflw3N3dp","colab_type":"text"},"cell_type":"markdown","source":["\n","---\n","# <font color=#003950 >Test and visualize the  word2vec model.</font>\n","---\n"]},{"metadata":{"id":"fCLKDuQRJeJN","colab_type":"code","colab":{}},"cell_type":"code","source":["vector_of_word=model['computer']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"F784YJSuJhEn","colab_type":"code","colab":{}},"cell_type":"code","source":["vector_of_word.shape"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8zi819woONPR","colab_type":"code","colab":{}},"cell_type":"code","source":["# Test the loaded word2vec model in gensim\n","# We will need the raw vector for a word\n","print(model['computer']) "],"execution_count":0,"outputs":[]},{"metadata":{"id":"mCm7bcUqOZpR","colab_type":"text"},"cell_type":"markdown","source":["## <font color=#003950 >We can explore similar/closer words</font>\n","---\n"]},{"metadata":{"id":"VR-A9adGHDqy","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","# We can get the words closest to a word\n","model.similar_by_word('computer')"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"2D9EI8USOyFU"},"cell_type":"markdown","source":["## <font color=#003950 >Now let's visualize a LIMITED number of tokens using t-SNE</font>\n","---\n"]},{"metadata":{"id":"IPoU785xMr2j","colab_type":"code","colab":{}},"cell_type":"code","source":["type(model.vocab)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TFuPtYVsMz_G","colab_type":"code","colab":{}},"cell_type":"code","source":["len(model.vocab)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SQk0e9yYJOY1","colab_type":"code","colab":{}},"cell_type":"code","source":["# Limit number of tokens to be visualized\n","limit = 500\n","vector_dim = 300\n","\n","# Getting tokens and vectors\n","words = []\n","embedding = np.array([])\n","i = 0\n","for word in model.vocab:\n","    # Break the loop if limit exceeds \n","    if i == limit: break\n","\n","    # Getting token \n","    words.append(word)\n","\n","    # Appending the vectors \n","    embedding = np.append(embedding, model[word])\n","\n","    i += 1\n","\n","# Reshaping the embedding vector \n","embedding = embedding.reshape(limit, vector_dim)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qDbitPriNDzv","colab_type":"code","colab":{}},"cell_type":"code","source":["embedding.shape"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Gc4tSx9iNIi3","colab_type":"code","colab":{}},"cell_type":"code","source":["len(words)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YdN3Gkc9NSfv","colab_type":"code","colab":{}},"cell_type":"code","source":["# Creating the tsne plot [Warning: will take time]\n","tsne = TSNE(perplexity=30.0, n_components=2, init='pca', n_iter=5000)\n","\n","low_dim_embedding = tsne.fit_transform(embedding)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"z2WFRyyCOZgM","colab_type":"code","colab":{}},"cell_type":"code","source":["i= 300\n","label=words[i]\n","\n","print('Word: ', label)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"G4qWNlN3OvK1","colab_type":"code","colab":{}},"cell_type":"code","source":["x, y = low_dim_embedding[i, :]\n","\n","print('X: ',x,' Y: ',y)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Tdszy5p_ORZ0","colab_type":"code","colab":{}},"cell_type":"code","source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(10, 10))  # in inches\n","\n","x, y = low_dim_embedding[i, :]\n","\n","plt.scatter(x, y)\n","\n","plt.annotate(label,\n","                 xy=(x, y),\n","                 xytext=(5, 2),\n","                 textcoords='offset points',\n","                 ha='right',\n","                 va='bottom')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"J2yuIIX0NZ9D","colab_type":"code","colab":{}},"cell_type":"code","source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","\n","def plot_with_labels(low_dim_embs, labels, filename='tsne.png'):\n","    assert low_dim_embs.shape[0] >= len(labels), \"More labels than embeddings\"\n","    plt.figure(figsize=(24, 24))  # in inches\n","    for i, label in enumerate(labels):\n","        x, y = low_dim_embs[i, :]\n","        plt.scatter(x, y)\n","        plt.annotate(label,\n","                 xy=(x, y),\n","                 xytext=(5, 2),\n","                 textcoords='offset points',\n","                 ha='right',\n","                 va='bottom')\n","    plt.savefig(filename)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"V6A15hozNgl-","colab_type":"code","colab":{}},"cell_type":"code","source":["# Finally plotting and saving the fig \n","plot_with_labels(low_dim_embedding, words)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yEHN3d8UJ2Sh","colab_type":"text"},"cell_type":"markdown","source":["\n","---\n","\n","---\n"]},{"metadata":{"colab_type":"text","id":"VzirNtmKPjnz"},"cell_type":"markdown","source":["## <font color=#003950 >...you could try with different databases(as Wiki) and NLP libraries...</font>\n","---\n"]},{"metadata":{"id":"VjlQUTJmJ7b3","colab_type":"text"},"cell_type":"markdown","source":["https://gist.github.com/manashmndl/bd75db5b8eb6f709b7a4c978027cfcd6\n","---\n","---\n","\n"]},{"metadata":{"id":"WCKXeW1JKqP0","colab_type":"text"},"cell_type":"markdown","source":["https://fasttext.cc/docs/en/pretrained-vectors.html\n","\n","Spanish\n","\n","https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.es.vec\n"]},{"metadata":{"id":"gi1SGolnKyPt","colab_type":"code","colab":{}},"cell_type":"code","source":["! wget -c \"https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.en.vec\""],"execution_count":0,"outputs":[]}]}